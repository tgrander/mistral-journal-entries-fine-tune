{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚¨áÔ∏è Step 1: Install Dependencies"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üßä pip freeze dependencies\n",
    "\n",
    "Only run this command when you have installed a new package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip freeze > requirements.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üì¶ pip install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19723.23s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "Collecting accelerate@ git+https://github.com/huggingface/accelerate.git@6719cb6db31f57ea5d2fdb179b0487f51718f353 (from -r requirements.txt (line 1))\n",
      "  Cloning https://github.com/huggingface/accelerate.git (to revision 6719cb6db31f57ea5d2fdb179b0487f51718f353) to /private/var/folders/v9/kls8l3fd0sb1gk104l1y05sh0000gn/T/pip-install-funimhq0/accelerate_10b4bf1299f64b49a6b5d0c2ba2e3da5\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/accelerate.git /private/var/folders/v9/kls8l3fd0sb1gk104l1y05sh0000gn/T/pip-install-funimhq0/accelerate_10b4bf1299f64b49a6b5d0c2ba2e3da5\n",
      "  Running command git rev-parse -q --verify 'sha^6719cb6db31f57ea5d2fdb179b0487f51718f353'\n",
      "  Running command git fetch -q https://github.com/huggingface/accelerate.git 6719cb6db31f57ea5d2fdb179b0487f51718f353\n",
      "  Running command git checkout -q 6719cb6db31f57ea5d2fdb179b0487f51718f353\n",
      "  Resolved https://github.com/huggingface/accelerate.git to commit 6719cb6db31f57ea5d2fdb179b0487f51718f353\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting en-core-web-sm@ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl#sha256=86cc141f63942d4b2c5fcee06630fd6f904788d2f0ab005cce45aadb8fb73889 (from -r requirements.txt (line 24))\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting peft@ git+https://github.com/huggingface/peft.git@62237dc9b1e460825462d6b1e7b0cf3418cec357 (from -r requirements.txt (line 56))\n",
      "  Cloning https://github.com/huggingface/peft.git (to revision 62237dc9b1e460825462d6b1e7b0cf3418cec357) to /private/var/folders/v9/kls8l3fd0sb1gk104l1y05sh0000gn/T/pip-install-funimhq0/peft_45a331965bc54522b2048ee52a9e4217\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/peft.git /private/var/folders/v9/kls8l3fd0sb1gk104l1y05sh0000gn/T/pip-install-funimhq0/peft_45a331965bc54522b2048ee52a9e4217\n",
      "  Running command git rev-parse -q --verify 'sha^62237dc9b1e460825462d6b1e7b0cf3418cec357'\n",
      "  Running command git fetch -q https://github.com/huggingface/peft.git 62237dc9b1e460825462d6b1e7b0cf3418cec357\n",
      "  Running command git checkout -q 62237dc9b1e460825462d6b1e7b0cf3418cec357\n",
      "  Resolved https://github.com/huggingface/peft.git to commit 62237dc9b1e460825462d6b1e7b0cf3418cec357\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting transformers@ git+https://github.com/huggingface/transformers.git@2c1eebc1216549d8195d7d1c6adb8b99afee3ec5 (from -r requirements.txt (line 97))\n",
      "  Cloning https://github.com/huggingface/transformers.git (to revision 2c1eebc1216549d8195d7d1c6adb8b99afee3ec5) to /private/var/folders/v9/kls8l3fd0sb1gk104l1y05sh0000gn/T/pip-install-funimhq0/transformers_55645ec8cf5a4669a2e6c98a4b628891\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /private/var/folders/v9/kls8l3fd0sb1gk104l1y05sh0000gn/T/pip-install-funimhq0/transformers_55645ec8cf5a4669a2e6c98a4b628891\n",
      "  Running command git rev-parse -q --verify 'sha^2c1eebc1216549d8195d7d1c6adb8b99afee3ec5'\n",
      "  Running command git fetch -q https://github.com/huggingface/transformers.git 2c1eebc1216549d8195d7d1c6adb8b99afee3ec5\n",
      "  Running command git checkout -q 2c1eebc1216549d8195d7d1c6adb8b99afee3ec5\n",
      "  Resolved https://github.com/huggingface/transformers.git to commit 2c1eebc1216549d8195d7d1c6adb8b99afee3ec5\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: aiohttp==3.9.1 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (3.9.1)\n",
      "Requirement already satisfied: aiosignal==1.3.1 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 3)) (1.3.1)\n",
      "Requirement already satisfied: annotated-types==0.6.0 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 4)) (0.6.0)\n",
      "Requirement already satisfied: appnope==0.1.3 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 5)) (0.1.3)\n",
      "Requirement already satisfied: asttokens==2.4.1 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 6)) (2.4.1)\n",
      "Requirement already satisfied: attrs==23.2.0 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 7)) (23.2.0)\n",
      "Requirement already satisfied: bitsandbytes==0.42.0 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 8)) (0.42.0)\n",
      "Requirement already satisfied: blis==0.7.11 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 9)) (0.7.11)\n",
      "Requirement already satisfied: catalogue==2.0.10 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 10)) (2.0.10)\n",
      "Requirement already satisfied: certifi==2023.11.17 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 11)) (2023.11.17)\n",
      "Requirement already satisfied: charset-normalizer==3.3.2 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 12)) (3.3.2)\n",
      "Requirement already satisfied: click==8.1.7 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 13)) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib==0.16.0 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 14)) (0.16.0)\n",
      "Requirement already satisfied: comm==0.2.1 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 15)) (0.2.1)\n",
      "Requirement already satisfied: confection==0.1.4 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 16)) (0.1.4)\n",
      "Requirement already satisfied: contourpy==1.2.0 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 17)) (1.2.0)\n",
      "Requirement already satisfied: cycler==0.12.1 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 18)) (0.12.1)\n",
      "Requirement already satisfied: cymem==2.0.8 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 19)) (2.0.8)\n",
      "Requirement already satisfied: datasets==2.16.1 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 20)) (2.16.1)\n",
      "Requirement already satisfied: debugpy==1.8.0 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 21)) (1.8.0)\n",
      "Requirement already satisfied: decorator==5.1.1 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 22)) (5.1.1)\n",
      "Requirement already satisfied: dill==0.3.7 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 23)) (0.3.7)\n",
      "Requirement already satisfied: executing==2.0.1 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 25)) (2.0.1)\n",
      "Requirement already satisfied: filelock==3.13.1 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 26)) (3.13.1)\n",
      "Requirement already satisfied: fonttools==4.47.2 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 27)) (4.47.2)\n",
      "Requirement already satisfied: frozenlist==1.4.1 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 28)) (1.4.1)\n",
      "Requirement already satisfied: fsspec==2023.10.0 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 29)) (2023.10.0)\n",
      "Requirement already satisfied: huggingface-hub==0.20.2 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 30)) (0.20.2)\n",
      "Requirement already satisfied: idna==3.6 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 31)) (3.6)\n",
      "Requirement already satisfied: ipykernel==6.29.0 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 32)) (6.29.0)\n",
      "Requirement already satisfied: ipython==8.20.0 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 33)) (8.20.0)\n",
      "Requirement already satisfied: ipywidgets==8.1.1 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 34)) (8.1.1)\n",
      "Requirement already satisfied: jedi==0.19.1 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 35)) (0.19.1)\n",
      "Requirement already satisfied: Jinja2==3.1.3 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 36)) (3.1.3)\n",
      "Requirement already satisfied: joblib==1.3.2 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 37)) (1.3.2)\n",
      "Requirement already satisfied: jupyter_client==8.6.0 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 38)) (8.6.0)\n",
      "Requirement already satisfied: jupyter_core==5.7.1 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 39)) (5.7.1)\n",
      "Requirement already satisfied: jupyterlab-widgets==3.0.9 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 40)) (3.0.9)\n",
      "Requirement already satisfied: kiwisolver==1.4.5 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 41)) (1.4.5)\n",
      "Requirement already satisfied: langcodes==3.3.0 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 42)) (3.3.0)\n",
      "Requirement already satisfied: MarkupSafe==2.1.3 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 43)) (2.1.3)\n",
      "Requirement already satisfied: matplotlib==3.8.2 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 44)) (3.8.2)\n",
      "Requirement already satisfied: matplotlib-inline==0.1.6 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 45)) (0.1.6)\n",
      "Requirement already satisfied: mpmath==1.3.0 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 46)) (1.3.0)\n",
      "Requirement already satisfied: multidict==6.0.4 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 47)) (6.0.4)\n",
      "Requirement already satisfied: multiprocess==0.70.15 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 48)) (0.70.15)\n",
      "Requirement already satisfied: murmurhash==1.0.10 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 49)) (1.0.10)\n",
      "Requirement already satisfied: nest-asyncio==1.5.9 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 50)) (1.5.9)\n",
      "Requirement already satisfied: networkx==3.2.1 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 51)) (3.2.1)\n",
      "Requirement already satisfied: numpy==1.26.3 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 52)) (1.26.3)\n",
      "Requirement already satisfied: packaging==23.2 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 53)) (23.2)\n",
      "Requirement already satisfied: pandas==2.1.4 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 54)) (2.1.4)\n",
      "Requirement already satisfied: parso==0.8.3 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 55)) (0.8.3)\n",
      "Requirement already satisfied: pexpect==4.9.0 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 57)) (4.9.0)\n",
      "Requirement already satisfied: pillow==10.2.0 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 58)) (10.2.0)\n",
      "Requirement already satisfied: platformdirs==4.1.0 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 59)) (4.1.0)\n",
      "Requirement already satisfied: preshed==3.0.9 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 60)) (3.0.9)\n",
      "Requirement already satisfied: prompt-toolkit==3.0.43 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 61)) (3.0.43)\n",
      "Requirement already satisfied: psutil==5.9.7 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 62)) (5.9.7)\n",
      "Requirement already satisfied: ptyprocess==0.7.0 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 63)) (0.7.0)\n",
      "Requirement already satisfied: pure-eval==0.2.2 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 64)) (0.2.2)\n",
      "Requirement already satisfied: pyarrow==14.0.2 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 65)) (14.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix==0.6 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 66)) (0.6)\n",
      "Requirement already satisfied: pydantic==2.5.3 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 67)) (2.5.3)\n",
      "Requirement already satisfied: pydantic_core==2.14.6 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 68)) (2.14.6)\n",
      "Requirement already satisfied: Pygments==2.17.2 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 69)) (2.17.2)\n",
      "Requirement already satisfied: pyparsing==3.1.1 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 70)) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil==2.8.2 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 71)) (2.8.2)\n",
      "Requirement already satisfied: python-dotenv==1.0.0 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 72)) (1.0.0)\n",
      "Requirement already satisfied: pytz==2023.3.post1 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 73)) (2023.3.post1)\n",
      "Requirement already satisfied: PyYAML==6.0.1 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 74)) (6.0.1)\n",
      "Requirement already satisfied: pyzmq==25.1.2 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 75)) (25.1.2)\n",
      "Requirement already satisfied: regex==2023.12.25 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 76)) (2023.12.25)\n",
      "Requirement already satisfied: requests==2.31.0 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 77)) (2.31.0)\n",
      "Requirement already satisfied: safetensors==0.4.1 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 78)) (0.4.1)\n",
      "Requirement already satisfied: scikit-learn==1.4.0 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 79)) (1.4.0)\n",
      "Requirement already satisfied: scipy==1.11.4 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 80)) (1.11.4)\n",
      "Requirement already satisfied: six==1.16.0 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 81)) (1.16.0)\n",
      "Requirement already satisfied: smart-open==6.4.0 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 82)) (6.4.0)\n",
      "Requirement already satisfied: spacy==3.7.2 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 83)) (3.7.2)\n",
      "Requirement already satisfied: spacy-legacy==3.0.12 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 84)) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers==1.0.5 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 85)) (1.0.5)\n",
      "Requirement already satisfied: srsly==2.4.8 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 86)) (2.4.8)\n",
      "Requirement already satisfied: stack-data==0.6.3 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 87)) (0.6.3)\n",
      "Requirement already satisfied: sympy==1.12 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 88)) (1.12)\n",
      "Requirement already satisfied: thinc==8.2.2 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 89)) (8.2.2)\n",
      "Requirement already satisfied: threadpoolctl==3.2.0 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 90)) (3.2.0)\n",
      "Requirement already satisfied: tokenizers==0.15.0 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 91)) (0.15.0)\n",
      "Requirement already satisfied: torch==2.1.2 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 92)) (2.1.2)\n",
      "Requirement already satisfied: torchvision==0.16.2 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 93)) (0.16.2)\n",
      "Requirement already satisfied: tornado==6.4 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 94)) (6.4)\n",
      "Requirement already satisfied: tqdm==4.66.1 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 95)) (4.66.1)\n",
      "Requirement already satisfied: traitlets==5.14.1 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 96)) (5.14.1)\n",
      "Requirement already satisfied: typer==0.9.0 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 98)) (0.9.0)\n",
      "Requirement already satisfied: typing_extensions==4.9.0 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 99)) (4.9.0)\n",
      "Requirement already satisfied: tzdata==2023.4 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 100)) (2023.4)\n",
      "Requirement already satisfied: urllib3==2.1.0 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 101)) (2.1.0)\n",
      "Requirement already satisfied: wasabi==1.1.2 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 102)) (1.1.2)\n",
      "Requirement already satisfied: wcwidth==0.2.13 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 103)) (0.2.13)\n",
      "Requirement already satisfied: weasel==0.3.4 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 104)) (0.3.4)\n",
      "Requirement already satisfied: widgetsnbextension==4.0.9 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 105)) (4.0.9)\n",
      "Requirement already satisfied: xxhash==3.4.1 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 106)) (3.4.1)\n",
      "Requirement already satisfied: yarl==1.9.4 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from -r requirements.txt (line 107)) (1.9.4)\n",
      "Requirement already satisfied: setuptools in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from spacy==3.7.2->-r requirements.txt (line 83)) (65.5.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19746.10s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "Collecting en-core-web-sm==3.7.1\n",
      "  Using cached https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "Requirement already satisfied: spacy<3.8.0,>=3.7.2 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from en-core-web-sm==3.7.1) (3.7.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.2)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.5.3)\n",
      "Requirement already satisfied: jinja2 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.3)\n",
      "Requirement already satisfied: setuptools in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (65.5.0)\n",
      "Requirement already satisfied: packaging>=20.0 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (23.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.14.6)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2023.11.17)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./env_journal_entries_mixtral/lib/python3.11/site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[38;5;2m‚úî Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from scripts.prepare_journals_for_training import process_files\n",
    "\n",
    "# Format each entry in journal_entries as {\"date\": \"2022-05-12\", \"note\": \"This is a journal entry.\"}\n",
    "journal_entries = process_files('data/raw/journal_entries/')\n",
    "\n",
    "# Save formatted entries to a JSONL file\n",
    "with open('data/processed/journal_entries.jsonl', 'w') as outfile:\n",
    "    for entry in journal_entries:\n",
    "        json.dump(entry, outfile)\n",
    "        outfile.write('\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All journal entries are in a single `.jsonl` file with the format:\n",
    "```json\n",
    "{\"date\": \"2022-05-12\", \"note\": \"This is a journal entry.\"}\n",
    "{\"date\": \"2022-05-13\", \"note\": \"This is a journal entry.\"}\n",
    "{\"date\": \"2022-05-14\", \"note\": \"This is a journal entry.\"}\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DataFrame from Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF Head\n",
      "         date                                               note\n",
      "0 2021-12-30  A porn addiction\\nPoor performance at work\\nNo...\n",
      "1 2022-03-27  You raped my childhood if any innocence it eve...\n",
      "2 2022-12-07                                                   \n",
      "3 2024-01-07  I have to admite something. Although i am sad ...\n",
      "4 2021-12-20                                                    \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json('data/processed/journal_entries.jsonl', lines=True)\n",
    "print(\"DF Head\\n\", df.head(), \"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Quality Check  \n",
    "\n",
    "Let's load the journal entries from a JSONL file into a pandas DataFrame and do the following: \n",
    "\n",
    "‚úÖ Display the first few rows of the DataFrame for an initial glance at the data.  \n",
    "‚úÖ Identify and report any missing values in key columns like date and note.  \n",
    "‚úÖ Ensure all date entries are in the correct Timestamp format.  \n",
    "‚úÖ Verify that all journal entries are formatted as strings.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column:\n",
      " date    0\n",
      "note    0\n",
      "dtype: int64\n",
      "\n",
      "Invalid dates found:\n",
      " Empty DataFrame\n",
      "Columns: [date, note]\n",
      "Index: []\n",
      "\n",
      "Non-string entries found:\n",
      " Empty DataFrame\n",
      "Columns: [date, note]\n",
      "Index: []\n",
      "\n",
      "Statistics for 'note' lengths:\n",
      " count      702.000000\n",
      "mean      2221.309117\n",
      "std       3101.092724\n",
      "min          0.000000\n",
      "25%        309.500000\n",
      "50%       1191.500000\n",
      "75%       3118.500000\n",
      "max      42126.000000\n",
      "Name: note, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in both date and note columns\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"Missing values in each column:\\n\", missing_values)\n",
    "\n",
    "# Validate Date Format - if the dates are already in Timestamp format, they are valid\n",
    "invalid_dates = df[~df['date'].apply(lambda x: isinstance(x, pd.Timestamp))]\n",
    "print(\"\\nInvalid dates found:\\n\", invalid_dates)\n",
    "\n",
    "# Check Journal Entry Format\n",
    "# Ensure that all journal entries are strings\n",
    "non_string_entries = df[~df['note'].apply(lambda x: isinstance(x, str))]\n",
    "print(\"\\nNon-string entries found:\\n\", non_string_entries)\n",
    "\n",
    "# Data Consistency and Completeness\n",
    "# Look for any anomalies in data, such as extremely short or long entries, or entries with unusual characters\n",
    "print(\"\\nStatistics for 'note' lengths:\\n\", df['note'].str.len().describe())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üïµüèΩ‚Äç‚ôÇÔ∏è Exploratory Data Analysis (EDA)\n",
    "\n",
    "We are curious about things like:\n",
    "\n",
    "1. Number of entries\n",
    "2. Average length of entries\n",
    "3. Minimum length of entry\n",
    "4. Maximum length of entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 702\n",
      "Average length of entries: 2221.309116809117\n",
      "Minimum length of entry: 0\n",
      "Maximum length of entry: 42126\n"
     ]
    }
   ],
   "source": [
    "num_entries = len(df)\n",
    "avg_length = df['note'].str.len().mean()\n",
    "min_length = df['note'].str.len().min()\n",
    "max_length = df['note'].str.len().max()\n",
    "\n",
    "print(f\"Number of entries: {num_entries}\")\n",
    "print(f\"Average length of entries: {avg_length}\")\n",
    "print(f\"Minimum length of entry: {min_length}\")\n",
    "print(f\"Maximum length of entry: {max_length}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The minimum entry length is 0, which means we have empty journal entries.  \n",
    "\n",
    "Training the model on blank entries won't do any good, so let's get rid of them."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üï≥Ô∏è Delete empty entries from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of empty entries: 0\n",
      "Number of empty entries: 0\n"
     ]
    }
   ],
   "source": [
    "# Filter empty entries\n",
    "empty_entries = df[df['note'].str.len() == 0]\n",
    "\n",
    "print(\"Number of empty entries:\", len(empty_entries))\n",
    "\n",
    "df = df[df['note'].str.len() > 0]\n",
    "\n",
    "empty_entries = df[df['note'].str.len() == 0]\n",
    "\n",
    "print(\"Number of empty entries:\", len(empty_entries))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now what's the minimum entry length?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum length of entry: 1\n"
     ]
    }
   ],
   "source": [
    "min_length = df['note'].str.len().min()\n",
    "\n",
    "print(f\"Minimum length of entry: {min_length}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìè Handle very short entries"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All empty entries are removed from dataset but there are still some very short ones. We should handle very short entries too. \n",
    "\n",
    "Let's visualize the distribution of entry lengths to get a feel for entry lengths as a whole. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate the length of each entry (in words)\n",
    "df['entry_length'] = df['note'].apply(lambda x: len(x.split()))\n",
    "\n",
    "# Plotting the histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df['entry_length'], bins=50, color='blue', edgecolor='black')\n",
    "plt.title('Distribution of Entry Lengths')\n",
    "plt.xlabel('Length of Entries (in words)')\n",
    "plt.ylabel('Number of Entries')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is evident that the majority of 702 entries are on the shorter side.\n",
    "\n",
    "Therefore short is the norm (long live the short king ü§¥üèΩ), but how short is too short? Let's set the threshold to 15 words and see what we get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of short entries: 58\n"
     ]
    }
   ],
   "source": [
    "word_count_threshold = 15\n",
    "\n",
    "short_entries = df[df['entry_length'] < word_count_threshold]\n",
    "\n",
    "print(\"Number of short entries:\", len(short_entries))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scan through the entries 10 at a time to see what these very short entries are like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 10)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_display = 10  # Set the maximum number of entries you want to display\n",
    "counter = 0\n",
    "\n",
    "counter, max_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entry 0:\n",
      " Far from a perfect year \n",
      "Left me hungry\n",
      "\n",
      "\n",
      "Entry 1:\n",
      " HMU about 30 mins before hand. 9173927850 -Stefan\n",
      "\n",
      "\n",
      "Entry 2:\n",
      " Damian Killa\n",
      "\n",
      "Last name: Killa\n",
      "\n",
      "\n",
      "Entry 3:\n",
      " I wasn‚Äôt done being bad.\n",
      "\n",
      "\n",
      "Entry 4:\n",
      " I can‚Äôt stop being a whore!! I NEED this vaccine!!!\n",
      "\n",
      "\n",
      "Entry 5:\n",
      " Between 3rd and Lexington\n",
      "Closer to third \n",
      "2nd floor\n",
      "\n",
      "8am\n",
      "\n",
      "\n",
      "Entry 6:\n",
      " * Writing course\n",
      "* Exercise\n",
      "* Look at LA apartments\n",
      "\n",
      "\n",
      "Entry 7:\n",
      " You can do better\n",
      "\n",
      "\n",
      "Entry 8:\n",
      " Study for coding interviews\n",
      "Google UX design course\n",
      "Pinesbnb\n",
      "\n",
      "\n",
      "Entry 9:\n",
      " This is a message to myself that I am writing openly.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10, 20)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "while True:\n",
    "    if counter >= max_display:\n",
    "        max_display += max_display \n",
    "        break\n",
    "    print(f\"Entry {counter}:\\n {short_entries.iloc[counter]['note']}\\n\\n\")\n",
    "    counter += 1\n",
    "\n",
    "counter, max_display"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After scanning them, I see there are some that are meaningless and some I want to keep.  \n",
    "\n",
    "Since there are only 58 of them, I am going to output them all with `ipywidgets` and choose `Keep` or `Delete` for each one.  \n",
    "\n",
    "If there were too many short_entries to do this, I could always just delete all short entries entirely.  \n",
    "\n",
    "However, since our dataset is already small and there are only 58 short entries, I will use this approach. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "entries_ix_to_delete = []\n",
    "entries_ix_to_delete = [40, 47, 65, 90, 103, 110, 117, 130, 132, 153, 156, 165, 171, 174, 205, 219, 247, 291, 292, 315, 318, 336, 342, 356, 385, 407, 424, 433, 451, 474, 530, 534, 541, 567, 578, 589, 602, 619, 620, 668, 690, 697]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Display the journal entry for a given index\n",
    "def show_entry_by_index(dataframe, index):\n",
    "    if index in dataframe.index:\n",
    "        entry = dataframe.loc[index]\n",
    "        print(f\"Index: {index}\")\n",
    "        print(f\"Date: {entry['date']}\")\n",
    "        print(\"Note:\")\n",
    "        print(entry['note'])\n",
    "    else:\n",
    "        print(f\"No entry found at index {index}\")\n",
    "\n",
    "def handle_entry_action(btn, ix, action):\n",
    "    if action == 'delete':\n",
    "        entries_ix_to_delete.append(ix)\n",
    "        btn.description = 'Marked for Deletion'\n",
    "    else:\n",
    "        btn.description = 'Kept'\n",
    "    \n",
    "    # Disable both buttons to prevent further interaction\n",
    "    for button in btn.container.children:\n",
    "        button.disabled = True\n",
    "\n",
    "for ix in short_entries.index.tolist():\n",
    "    show_entry_by_index(df, ix)\n",
    "\n",
    "    # Create a container for buttons\n",
    "    button_container = widgets.HBox()\n",
    "    \n",
    "    # Create a delete button\n",
    "    delete_btn = widgets.Button(description=\"Delete\")\n",
    "    delete_btn.container = button_container\n",
    "    delete_btn.on_click(lambda btn, ix=ix: handle_entry_action(btn, ix, 'delete'))\n",
    "\n",
    "    # Create a keep button\n",
    "    keep_btn = widgets.Button(description=\"Keep\")\n",
    "    keep_btn.container = button_container\n",
    "    keep_btn.on_click(lambda btn, ix=ix: handle_entry_action(btn, ix, 'keep'))\n",
    "\n",
    "    # Add buttons to the container\n",
    "    button_container.children = [delete_btn, keep_btn]\n",
    "    \n",
    "    display(button_container)\n",
    "\n",
    "    # Separate the entries for readability\n",
    "    print(\"\\n\" + \"-\"*40 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num short entries:  58\n",
      "Num short entries to delete:  42\n"
     ]
    }
   ],
   "source": [
    "print(\"Num short entries: \", len(short_entries))\n",
    "print(\"Num short entries to delete: \", len(entries_ix_to_delete))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indexes of short entries to delete ends up being: \n",
    "\n",
    "`[40, 47, 65, 90, 103, 110, 117, 130, 132, 153, 156, 165, 171, 174, 205, 219, 247, 291, 292, 315, 318, 336, 342, 356, 385, 407, 424, 433, 451, 474, 530, 534, 541, 567, 578, 589, 602, 619, 620, 668, 690, 697]`\n",
    "\n",
    "Let's delete them üöÆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexes to delete: [40, 47, 65, 90, 103, 110, 117, 130, 132, 153, 156, 165, 171, 174, 205, 219, 247, 291, 292, 315, 318, 336, 342, 356, 385, 407, 424, 433, 451, 474, 530, 534, 541, 567, 578, 589, 602, 619, 620, 668, 690, 697]\n",
      "Number of entries to delete: 42\n",
      "Number of entries in DataFrame before delete: 668\n",
      "Number of entries in DataFrame after delete: 626\n"
     ]
    }
   ],
   "source": [
    "print(\"Indexes to delete:\", entries_ix_to_delete)\n",
    "print(\"Number of entries to delete:\", len(entries_ix_to_delete))\n",
    "print(\"Number of entries in DataFrame before delete:\", len(df))\n",
    "\n",
    "# Remove the short entries listed in entries_ix_to_delete from the DataFrame\n",
    "df = df.drop(entries_ix_to_delete)\n",
    "\n",
    "# Reset the index if you want a continuous index after deletion\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "print(\"Number of entries in DataFrame after delete:\", len(df))\n",
    "\n",
    "# Now df_dropped is your DataFrame with the specified entries removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many short entries remain?\n",
    "len(df[df['entry_length'] < word_count_threshold])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üêç Handle very long entries"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The stats of the entry data showed a large distribution in the sizes of the entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 626\n",
      "Average length of entries: 2488.011182108626\n",
      "Minimum length of entry: 13\n",
      "Maximum length of entry: 42126\n"
     ]
    }
   ],
   "source": [
    "num_entries = len(df)\n",
    "avg_length = df['note'].str.len().mean()\n",
    "min_length = df['note'].str.len().min()\n",
    "max_length = df['note'].str.len().max()\n",
    "\n",
    "print(f\"Number of entries: {num_entries}\")\n",
    "print(f\"Average length of entries: {avg_length}\")\n",
    "print(f\"Minimum length of entry: {min_length}\")\n",
    "print(f\"Maximum length of entry: {max_length}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importance of handling very long entries:**\n",
    "\n",
    "1. Model Constraints: Models have token limits; long entries might get truncated, losing vital information.\n",
    "2. Resource Efficiency: Longer entries consume more computational resources, impacting training efficiency.\n",
    "3. Data Skewness: Extremely long entries can skew the model's understanding, affecting its performance on typical cases."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we do next will benefit from using a formatted and tokenized dataset, so let's do those two things before proceeding with the rest of handling very long entries. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Format the Prompts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format each journal entry with a custom header indicating it's a note by Eevee the Dog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatting_func(row):\n",
    "    # I'm keeping Eevee the Dog bc it's cute and I couldn't think of anything better\n",
    "    formatted_text = f\"### Date: {row['date']} \\n### Note by Eevee the Dog:\\n {row['note']}\"\n",
    "    return formatted_text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ü§î Why format training examples this way?\n",
    "\n",
    "A properly formatted prompt is crucial in effectively training the model and being able to interact with the model in the intended ways.  \n",
    "\n",
    "Formatting the prompt this way allows us to prompt the fine-tuned model based on the following strategies."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompting Strategies for the Fine-Tuned Model\n",
    "\n",
    "Our objective is to effectively prompt the fine-tuned model to generate responses based on the trained journal entries.   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Header Variability  \n",
    "\n",
    "Employ different versions of the header, keeping the core idea intact. Examples include \"Eevee the Dog wrote the following note:\" or simply \"Note by Eevee the Dog.\"\n",
    "\n",
    "### Thematic Prompts  \n",
    "\n",
    "Utilize themes or contexts from the journal entries to guide the model's responses. For instance, \"Reflecting on a day in the park, Eevee the Dog noted:\" or \"In a mood of contemplation, Eevee the Dog wrote:\"\n",
    "\n",
    "### Questions and Statements  \n",
    "\n",
    "Directly engage with the content using questions or statements, like \"What did Eevee the Dog say about his adventures today?\" or \"Describe a recent experience of Eevee the Dog.\"\n",
    "\n",
    "### Keyword Focus  \n",
    "\n",
    "Use prevalent keywords or topics from the entries as prompts, such as \"Discuss Eevee the Dog's thoughts on happiness,\" or \"Eevee the Dog's perspective on friendship.\"\n",
    "\n",
    "### Narrative Starters  \n",
    "\n",
    "Begin with narrative prompts in line with the journal's style, like \"Once upon a time, Eevee the Dog felt...\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Formatting Function to Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      ### Date: 2021-12-30 00:00:00 \\n### Note by Ee...\n",
       "1      ### Date: 2022-03-27 00:00:00 \\n### Note by Ee...\n",
       "2      ### Date: 2024-01-07 00:00:00 \\n### Note by Ee...\n",
       "3      ### Date: 2023-03-02 00:00:00 \\n### Note by Ee...\n",
       "4      ### Date: 2023-04-10 00:00:00 \\n### Note by Ee...\n",
       "                             ...                        \n",
       "621    ### Date: 2021-09-03 00:00:00 \\n### Note by Ee...\n",
       "622    ### Date: 2021-08-21 00:00:00 \\n### Note by Ee...\n",
       "623    ### Date: 2023-02-27 00:00:00 \\n### Note by Ee...\n",
       "624    ### Date: 2022-05-23 00:00:00 \\n### Note by Ee...\n",
       "625    ### Date: 2021-08-10 00:00:00 \\n### Note by Ee...\n",
       "Name: formatted, Length: 626, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df['formatted'] = df.apply(formatting_func, axis=1)\n",
    "# df['formatted']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step: ü§ñ Load the Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nf4_config' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 17\u001b[0m\n\u001b[1;32m      4\u001b[0m base_model_id \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mTheBloke/dolphin-2.5-mixtral-8x7b-GGUF\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[39m# UNCOMMENT BELOW TO LOAD MODEL\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39m# -----------------------------\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[39m# nf4_config = BitsAndBytesConfig(\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39m#     bnb_4bit_compute_dtype=torch.bfloat16\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[39m# )\u001b[39;00m\n\u001b[1;32m     15\u001b[0m model \u001b[39m=\u001b[39m AutoModelForCausalLM\u001b[39m.\u001b[39mfrom_pretrained(\n\u001b[1;32m     16\u001b[0m     base_model_id, \n\u001b[0;32m---> 17\u001b[0m     quantization_config\u001b[39m=\u001b[39mnf4_config, \n\u001b[1;32m     18\u001b[0m     device_map\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     19\u001b[0m     use_cache\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     20\u001b[0m     attention_implementation\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mflash_attention_2\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     21\u001b[0m )\n\u001b[1;32m     23\u001b[0m \u001b[39m# Set the device to GPU (if available)\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[39m# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[39m# model.to(device)\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nf4_config' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "base_model_id = \"TheBloke/dolphin-2.5-mixtral-8x7b-GGUF\"\n",
    "\n",
    "# UNCOMMENT BELOW TO LOAD MODEL\n",
    "# -----------------------------\n",
    "# nf4_config = BitsAndBytesConfig(\n",
    "#     load_in_4bit=True,\n",
    "#     bnb_4bit_use_double_quant=True,\n",
    "#     bnb_4bit_quant_type=\"nf4\",\n",
    "#     bnb_4bit_compute_dtype=torch.bfloat16\n",
    "# )\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_id, \n",
    "    quantization_config=nf4_config, \n",
    "    device_map=\"auto\",\n",
    "    use_cache=False,\n",
    "    attention_implementation=\"flash_attention_2\"\n",
    ")\n",
    "\n",
    "# Set the device to GPU (if available)\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model.to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step: ü™ô Load Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer_model_id = \"mistralai/Mixtral-8x7B-v0.1\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_model_id)\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "tokenizer.add_eos_token = True\n",
    "tokenizer.add_bos_token = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize Formatted Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_tokenize_row(row):\n",
    "    result = tokenizer(\n",
    "        formatting_func(row),\n",
    "        # truncation=True,\n",
    "        # max_length=max_length,\n",
    "        # padding=\"max_length\",\n",
    "    )\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tokens(row):\n",
    "    # Tokenize the entry and return the count of tokens\n",
    "    tokenized = tokenizer(formatting_func(row))\n",
    "    return len(tokenized['input_ids'])\n",
    "\n",
    "df['token_count'] = df.apply(count_tokens, axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step: Determine Max Sequence Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count      626.000000\n",
      "mean       655.108626\n",
      "std        785.571473\n",
      "min         40.000000\n",
      "25%        166.750000\n",
      "50%        401.000000\n",
      "75%        878.000000\n",
      "max      10621.000000\n",
      "Name: token_count, dtype: float64\n",
      "Proposed threshold for very long entries: 1976.25 tokens\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of very long entries: 32\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Descriptive statistics to understand the distribution\n",
    "print(df['token_count'].describe())\n",
    "\n",
    "# Identify a potential threshold for long entries, e.g., using the 95th percentile\n",
    "token_threshold = df['token_count'].quantile(0.95)\n",
    "print(f\"Proposed threshold for very long entries: {token_threshold} tokens\")\n",
    "\n",
    "# Dynamic binning for histogram based on token data range\n",
    "bin_width = int(np.ceil((df['token_count'].max() - df['token_count'].min()) / 30))\n",
    "bins = range(int(df['token_count'].min()), int(df['token_count'].max()) + bin_width, bin_width)\n",
    "\n",
    "# Plotting a histogram for visual analysis\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df['token_count'], bins=bins, color='blue', alpha=0.7)\n",
    "plt.axvline(token_threshold, color='red', linestyle='dashed', linewidth=2)\n",
    "plt.title('Token Count Distribution in Journal Entries')\n",
    "plt.xlabel('Token Count')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Filtering the DataFrame for very long entries based on token count\n",
    "long_entries_df = df[df['token_count'] > token_threshold]\n",
    "print(f\"Number of very long entries: {len(long_entries_df)}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Propsed threshold is ~1900 tokens however this seems a bit long as the standard for many modes is only 512 tokens.\n",
    "\n",
    "Let's stay in the range of 1900 but decrease to 1500. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Max Sequence Length\n",
    "\n",
    "`max_sequence_length` should cover most of the training examples but should also not be too big. The bigger `max_sequence_length`, the more compute resources and time required to train the model.\n",
    "\n",
    "The goal is to choose the smallest possible `max_sequence_length` the covers the majority of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[122], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m max_sequence_length \u001b[39m=\u001b[39m \u001b[39m1500\u001b[39m \u001b[39m# tokens\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m# prompt_token_count = tokenizer(formatting_func(\"\"))\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[39mprint\u001b[39m(formatting_func(\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n",
      "Cell \u001b[0;32mIn[111], line 3\u001b[0m, in \u001b[0;36mformatting_func\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mformatting_func\u001b[39m(row):\n\u001b[1;32m      2\u001b[0m     \u001b[39m# I'm keeping Eevee the Dog bc it's cute and I couldn't think of anything better\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     formatted_text \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m### Date: \u001b[39m\u001b[39m{\u001b[39;00mrow[\u001b[39m'\u001b[39;49m\u001b[39mdate\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m### Note by Eevee the Dog: \u001b[39m\u001b[39m{\u001b[39;00mrow[\u001b[39m'\u001b[39m\u001b[39mnote\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m     \u001b[39mreturn\u001b[39;00m formatted_text\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers, not 'str'"
     ]
    }
   ],
   "source": [
    "# max_sequence_length = 1900 # tokens\n",
    "max_sequence_length = 1500 # tokens\n",
    "\n",
    "# prompt_token_count = tokenizer(formatting_func(\"\"))\n",
    "\n",
    "print(formatting_func(\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of very long entries: 62\n"
     ]
    }
   ],
   "source": [
    "long_entries_df = df[df['token_count'] > max_sequence_length]\n",
    "print(f\"Number of very long entries: {len(long_entries_df)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úÇÔ∏è Split longer entries into smaller subsets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Include a small overlap (e.g., part of the last sentence from the previous segment) in each new segment.  \n",
    "\n",
    "This overlap can help maintain context continuity across segments, especially if the segmentation cuts through important narrative or thematic elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def segment_entry(row, max_token_length=max_sequence_length):\n",
    "    \"\"\"\n",
    "    Segments a long journal entry into smaller parts based on token count and natural sentence boundaries.\n",
    "\n",
    "    Args:\n",
    "    entry (str): The journal entry to be segmented.\n",
    "    max_token_length (int): The maximum token length for each segment.\n",
    "\n",
    "    Returns:\n",
    "    List[str]: A list of segmented journal entries.\n",
    "    \"\"\"\n",
    "    prompt_template = f\"### Date: {row['date']} \\n### Note by Eevee the Dog:\\n\"\n",
    "    prompt_tokens = tokenizer.tokenize(prompt_template)\n",
    "\n",
    "    doc = nlp(row[\"note\"])\n",
    "    segments = []\n",
    "    current_tokens = []\n",
    "\n",
    "    for sent in doc.sents:\n",
    "        # Tokenize the sentence\n",
    "        sentence_tokens = tokenizer.tokenize(sent.text)\n",
    "\n",
    "        if len(prompt_tokens) + len(current_tokens) + len(sentence_tokens) > max_token_length:\n",
    "            # Convert current segment to text and store it\n",
    "            segment_text = tokenizer.convert_tokens_to_string(current_tokens)\n",
    "            segments.append(segment_text.strip())\n",
    "            \n",
    "            # Start new segment with prompt tokens and current sentence\n",
    "            # current_tokens = prompt_tokens.copy() + sentence_tokens\n",
    "            current_tokens = sentence_tokens\n",
    "        else:\n",
    "            current_tokens.extend(sentence_tokens)\n",
    "\n",
    "    # Add the last segment if not empty\n",
    "    if current_tokens:\n",
    "        segment_text = tokenizer.convert_tokens_to_string(current_tokens).strip()\n",
    "        segments.append(segment_text)\n",
    "\n",
    "    return segments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üçä Segment 1:\n",
      "I did not wake up at 6:30 as my alarm clock intended however I was lights out and in bed at 10:30. Unfortunately I was arguing with Josh in my head until midnight. I ended up having an incredible day. I woke up rested, I wrote a shit ton, went on a thirty minute walk and thought good thoughts. \n",
      "\n",
      " Worked on my second brain. \n",
      " Came to some good conclusions. \n",
      " One of which I started writing about yesterday. \n",
      " Stop giving so many fucks! \n",
      " My whole world was Jason and Josh and it consumed me. \n",
      " Going to George‚Äôs pool party reminded me of all the connections there are to be made out there. \n",
      " All the wonderful people. \n",
      " There is a whole world out there fay beyond our little exclusive friend group. \n",
      " Far beyond LA. \n",
      " A whole great, big world with all kinds of adventures and explorations. \n",
      "\n",
      " I was sitting in the backyard yesterday when josh and Jason came home. \n",
      " Josh came to the back door and we had a little exchange. \n",
      " I complimented his shorts. He told me where he got them. \n",
      " ‚ÄúCute‚Äù I remarked. \n",
      "\n",
      " Jason was sitting on the couch with that look on his face. \n",
      " Pensive, dissociated‚Ä¶ it‚Äôs when little bb needs love. \n",
      " ‚ÄúHow was your day, JJ?‚Äù I asked. \n",
      " ‚ÄúIt was ok,‚Äù he responded without changing the direction or expression of his face. \n",
      "\n",
      " ‚ÄúCome,‚Äù I called out to him with my arms open wide. \n",
      " He came. I pulled him in close when my arms were around him. \n",
      " I love him so much. \n",
      " Josh said to me this past Friday while Jason was not there..\n",
      "‚ÄúBased on the way you are reacting, it‚Äôs obvious that you love Jason.‚Äù\n",
      "I do. \n",
      " I do love Jason.\n",
      " And I told him yesterday when he sat with me in the back yard, ‚Äúit feels really good to have the kind of love I have for you.‚Äù \n",
      " It‚Äôs the kind of love that reminds what love really is when there‚Äôs no possession, no desire to control. \n",
      " To truly just love someone and therefore want the best for them. \n",
      " But I am not in love. \n",
      " I could have gotten there. \n",
      " I almost got there. \n",
      " I dipped my toe in the water. \n",
      " But I pulled back. We did. \n",
      " And of course I still feel something. I will always love him. And not a single part of me feels shame about that. \n",
      "\n",
      " Yesterday he looked so handsome. ‚ÄúYou look healthy and young,‚Äù I told him. \n",
      " ‚ÄúI like the young part,‚Äù he remarked and laughed. \n",
      "\n",
      " ‚ÄúYou seem pensive today. What‚Äôs up?‚Äù I asked. \n",
      " And he told me. \n",
      " He called his dad the night of his birthday and spoke to him for two hours. \n",
      " He said that he could see the emotional immaturity of his father in the way that he spoke. And it was understanding the stunted growth of his father that allowed him to pass through his resentment, anger and pain into love. \n",
      " Right now, Jason is seeking the answers. \n",
      " ‚ÄúI want to do the work. I want to live in reality. I don‚Äôt want to live in this fantasy I created of what I think and want the world to be.‚Äù\n",
      " He said it with such conviction and a hint of self flagellation because he is hard on himself. \n",
      " I felt proud of my boy. I felt proud of me, too. I could hear my influence on him to embrace the struggle, to clean out the heaps of dust swept under the carpet in the name of ‚Äúkeeping the peace‚Äù only to haunt us later in ten fold. \n",
      "\n",
      " A lot happened to Jason on his birthday. \n",
      " His ex boyfriend came over and they got into a fight.\n",
      " In the aftermath of the fight, Jason was flustered and left home in a rush, leaving a candle burning. \n",
      " The candle burned a hole into a book in his room on which it was perched. \n",
      " His live-in landlord, Loy‚Äîan acquaintance of ours, smelled the burning and discovered the candle, which could have burned the house down. \n",
      " Jason arrived at my place with Josh after the mall. \n",
      " I was in a ghastly mood. Josh and I had just gotten into a fight, during which I said for the umpteenth time this week, ‚ÄúI‚Äôm done.‚Äù\n",
      " And honestly, I think I meant it. \n",
      " We got into an Uber to George Harlow‚Äôs birthday pool party. I was silent for most of the ride and staring blankly out the window. \n",
      " Loy confronted Jason at the pool party we were at and kicked him out of the house. \n",
      " Loy apologized for it all going down on Jason‚Äôs birthday but things escalated and Loy began yelling at Jason at the party. \n",
      " Jason questions what he did to deserve all of this. He felt like his life was crumbling around him. \n",
      " Josh gave dumbass ‚Äúeverything will be fine‚Äù and ‚Äúmaybe it happened for a reason‚Äù input. \n",
      " Jason waved it away. \n",
      " I comforted him by listening, letting him speak and physical touch with my hand gripping his thigh. \n",
      " Back at my place, Jason went straight upstairs and got under the covers in my bed. \n",
      " He asked me to join him and for five wonderful minutes, I held him. \n",
      " He scooted closer. \n",
      " And despite it all, he let it all go and had a wonderful night. \n",
      " ‚ÄúIt was incredible to see you smile and enjoy yourself on your birthday despite it all,‚Äù I told him. \n",
      "\n",
      " He asked how my day was and I told him: it was beautiful. \n",
      " A lot happened to me yesterday, too. \n",
      " The fight with Josh, the pool party, Jason‚Äôs birthday dinner, Clint‚Äôs afterward, and that familiar dark energy that seeped out of Josh at the very end of the night for reason‚Äôs I cannot be sure but they always seem to be when I am shining brightly and he isn‚Äôt. \n",
      "\n",
      " After all that. \n",
      " After three weeks of anxiety and depression. \n",
      " Waking up dreading the day. \n",
      " Going to bed at 3am because of having to face that dread in the morning. \n",
      " The cataclysmic fallout with Josh. \n",
      " Sort of falling for Jason and then finding even more comfort in the safety of our boundaries as friends instead of lovers.\n",
      "\n",
      "\n",
      "üçä Segment 2:\n",
      "The disappearance of Adriano as a friend from my life after spending two back to back vacations together bonding, laughing and telling each other ‚ÄúI love you‚Äù. \n",
      " After Josh revealing to me that he thought I was a dark witch casting evil spells on him and our friends. \n",
      " After all that.\n",
      " What I learned is simple but will change my life if I implement it. \n",
      "\n",
      " **Find every fuck you give and set them free. **\n",
      "\n",
      "If Josh gets Jason a fancy birthday present, I don‚Äôt give a fuck. \n",
      " If Jason and Josh go to dinner with Adriano and Clint without me, I don‚Äôt give a fuck. \n",
      " If Jason wants to reattach to Josh‚Äôs teet and suckle on on the milk of his manipulation, I don‚Äôt give a fuck. \n",
      " If I‚Äôm not included, I don‚Äôt give a fuck. \n",
      " If I‚Äôm misunderstood, I don‚Äôt give a fuck. \n",
      " If I‚Äôm called a dark witch behind my back, I don‚Äôt give a fuck. \n",
      "\n",
      " I don‚Äôt give a fuck. \n",
      " I don‚Äôt give a fuck. \n",
      " I don‚Äôt give a fuck. \n",
      " I don‚Äôt give a fuck. \n",
      " I DON‚ÄôT GIVE A FUCK. \n",
      "\n",
      " And the trick to not giving a fuck but still being a good person is to always live with kindness and love. If you show up and you do your best and you treat people with kindness and love while respecting the boundaries you‚Äôve set‚Ä¶ then baby, you got nothing to worry about. \n",
      "\n",
      " Be present, smile, have fun and make people feel seen in your presence. Show them that you see them and show them that you care. Be vulnerable so that they can see you, too. If you do those things then you can throw every fuck you give out the window and leave a situation knowing that you did your best and that you can sleep well tonight with a calm, quiet and fuck-less mind. You deserve that. \n",
      "\n",
      " **How did I get here? **\n",
      "\n",
      "My life the past two months has been a strange one. \n",
      " So much tension accumulated that it resulted in a magnitude 10 earthquake that shook the foundation of my life to its core. \n",
      " After surviving that kind of disaster, you stand up and look at the carnage around you. \n",
      " Everything felt destroyed. \n",
      " Everything that I thought I knew was in pieces at my feet. \n",
      " And I asked myself, what did I do to deserve this?\n",
      " And if I did deserve this‚Ä¶ if it were my actions that made this mess, then what does that say about me as a person?\n",
      " In the wake of what I thought was the collapse of life as I knew it, I descended into a spiral of intrusive thoughts and depression. \n",
      " I did all the reflection; I wrote tens of thousands of words to try and understand it all. \n",
      " The clouds of this depression were heavy and dark. \n",
      " Giant, black nebulous clouds that released a storm of rain and thunder.\n",
      " But just like the earthquake, I survived the storm, too. \n",
      " All that wind and rain washed away the rubble of the old life and this time when I stood up and looked around me,\n",
      "There was nothing.\n",
      " Only I remained. \n",
      "\n",
      " When depressed, I forget what it feels like to be happy. \n",
      " The days when I opened my eyes and simply felt good seem mythical. \n",
      " But then those storm clouds begin to diffuse and finally, one sliver of sunshine makes its way through. \n",
      " I saw it, I felt it, I danced in it and and said to myself, \n",
      "‚ÄúAh, this is what it feels like. I remember now.‚Äù\n",
      "\n",
      " The clouds of my depression passed and I was sitting in my back yard on a Sunday afternoon just happy to be alive. \n",
      " A close friend joined me and after his own reflection on the earthquake that shook both our lives to their cores, he said this: \n",
      "‚ÄúWhen shit falls apart, all you can do is rebuild. \n",
      " Something better and stronger than what existed before. \n",
      " And that is what I am going to do.‚Äù\n",
      "\n",
      " Amen.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Selecting the first long entry for demonstration\n",
    "long_entry = long_entries_df.iloc[0]\n",
    "\n",
    "segments = segment_entry(long_entry)\n",
    "\n",
    "# Print the segmented entries\n",
    "for i, segment in enumerate(segments, 1):\n",
    "    print(f\"üçä Segment {i}:\\n{segment}\\n\\n\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply segmentation to entire DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>note</th>\n",
       "      <th>entry_length</th>\n",
       "      <th>token_count</th>\n",
       "      <th>segments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-04-10</td>\n",
       "      <td>I did not wake up at 6:30 as my alarm clock in...</td>\n",
       "      <td>1687</td>\n",
       "      <td>2397</td>\n",
       "      <td>[I did not wake up at 6:30 as my alarm clock i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023-04-07</td>\n",
       "      <td>It‚Äôs been a tough couple weeks. \\nYesterday, t...</td>\n",
       "      <td>1356</td>\n",
       "      <td>1785</td>\n",
       "      <td>[It‚Äôs been a tough couple weeks. \\n Yesterday,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2021-09-27</td>\n",
       "      <td>Letting myself be happy\\nWas key\\nTo invite in...</td>\n",
       "      <td>1794</td>\n",
       "      <td>2790</td>\n",
       "      <td>[Letting myself be happy\\nWas key\\nTo invite i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2021-05-18</td>\n",
       "      <td>And I know that it will get what it want if it...</td>\n",
       "      <td>2169</td>\n",
       "      <td>2715</td>\n",
       "      <td>[And I know that it will get what it want if i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2023-03-01</td>\n",
       "      <td>I‚Äôm doing my best. And my best begins with bei...</td>\n",
       "      <td>1728</td>\n",
       "      <td>2138</td>\n",
       "      <td>[I‚Äôm doing my best. And my best begins with be...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                                               note  \\\n",
       "4  2023-04-10  I did not wake up at 6:30 as my alarm clock in...   \n",
       "9  2023-04-07  It‚Äôs been a tough couple weeks. \\nYesterday, t...   \n",
       "14 2021-09-27  Letting myself be happy\\nWas key\\nTo invite in...   \n",
       "23 2021-05-18  And I know that it will get what it want if it...   \n",
       "39 2023-03-01  I‚Äôm doing my best. And my best begins with bei...   \n",
       "\n",
       "    entry_length  token_count  \\\n",
       "4           1687         2397   \n",
       "9           1356         1785   \n",
       "14          1794         2790   \n",
       "23          2169         2715   \n",
       "39          1728         2138   \n",
       "\n",
       "                                             segments  \n",
       "4   [I did not wake up at 6:30 as my alarm clock i...  \n",
       "9   [It‚Äôs been a tough couple weeks. \\n Yesterday,...  \n",
       "14  [Letting myself be happy\\nWas key\\nTo invite i...  \n",
       "23  [And I know that it will get what it want if i...  \n",
       "39  [I‚Äôm doing my best. And my best begins with be...  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply segmentation to each row in long_entries_df\n",
    "segmented_series = long_entries_df.apply(segment_entry, axis=1)\n",
    "long_entries_df = long_entries_df.assign(segments=segmented_series)\n",
    "\n",
    "# Now, long_entries_df has a new column 'segments' containing the segmented entries\n",
    "long_entries_df.head()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üñáÔ∏è Integrate Segments Into Training Data\n",
    "\n",
    "ü•û **Flatten the Segmented Data**  \n",
    "  \n",
    "Since `long_entries_df['segments']` now contains lists of segments, flatten these lists so that each segment becomes a separate row in a new DataFrame.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date                                               note\n",
      "0 2023-04-10  I did not wake up at 6:30 as my alarm clock in...\n",
      "1 2023-04-10  The disappearance of Adriano as a friend from ...\n",
      "2 2023-04-07  It‚Äôs been a tough couple weeks. \\n Yesterday, ...\n",
      "3 2023-04-07  My hunger filled my body like the steam of a s...\n",
      "4 2021-09-27  Letting myself be happy\\nWas key\\nTo invite in...\n"
     ]
    }
   ],
   "source": [
    "# Flatten the DataFrame\n",
    "flattened_df = pd.DataFrame([(date, segment) \n",
    "                             for date, segments in zip(long_entries_df['date'], long_entries_df['segments'])\n",
    "                             for segment in segments], \n",
    "                            columns=['date', 'note'])\n",
    "\n",
    "# Display the new DataFrame structure\n",
    "print(flattened_df.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop the long entries from the original DataFrame.  \n",
    "\n",
    "Before concatenating, make sure the columns in flattened_df and df_shortened align."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in df_shortened: Index(['date', 'note', 'entry_length', 'token_count'], dtype='object')\n",
      "Columns in flattened_df: Index(['date', 'note'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Drop the original long entries from the original DataFrame\n",
    "df_shortened = df.drop(long_entries_df.index)\n",
    "\n",
    "# Before concatenating, make sure the columns in flattened_df and df_shortened align\n",
    "# They should both have the same columns, e.g., 'date' and 'note'\n",
    "print(\"Columns in df_shortened:\", df_shortened.columns)\n",
    "print(\"Columns in flattened_df:\", flattened_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in df_shortened: Index(['date', 'note'], dtype='object')\n",
      "Columns in flattened_df: Index(['date', 'note'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Select relevant columns from df_shortened to match flattened_df\n",
    "df_shortened = df_shortened[['date', 'note']]\n",
    "\n",
    "print(\"Columns in df_shortened:\", df_shortened.columns)\n",
    "print(\"Columns in flattened_df:\", flattened_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate df_shortened_aligned and flattened_df\n",
    "combined_df = pd.concat([df_shortened, flattened_df], ignore_index=True)\n",
    "\n",
    "# Display the combined DataFrame structure\n",
    "print(combined_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates based on the 'note' column\n",
    "duplicates = combined_df[combined_df.duplicated(subset=['note'], keep=False)]\n",
    "print(duplicates)\n",
    "\n",
    "# Drop duplicates based on the 'note' column\n",
    "unique_df = combined_df.drop_duplicates(subset=['note'])\n",
    "\n",
    "# Display the structure of the unique DataFrame\n",
    "print(unique_df.head())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify no more duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [date, note]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "duplicates = unique_df[unique_df.duplicated(subset=['note'], keep=False)]\n",
    "print(duplicates)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step: Prepare Data for Training\n",
    "Convert the final DataFrame into a Hugging Face Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = combined_df[['date', 'note']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['date', 'note'],\n",
       "    num_rows: 704\n",
       "})"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "# Convert the DataFrame into a Hugging Face Dataset\n",
    "dataset = Dataset.from_pandas(final_df)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Split Data into Train and Validation Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set:\n",
      "Dataset({\n",
      "    features: ['date', 'note'],\n",
      "    num_rows: 633\n",
      "})\n",
      "Validation Set:\n",
      "Dataset({\n",
      "    features: ['date', 'note'],\n",
      "    num_rows: 71\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training and validation sets\n",
    "train_test_split_ratio = 0.9  # 90% for training, 10% for validation\n",
    "split_datasets = dataset.train_test_split(test_size=(1 - train_test_split_ratio))\n",
    "\n",
    "train_dataset = split_datasets['train']\n",
    "eval_dataset = split_datasets['test']\n",
    "\n",
    "# Checking the first few examples of the training and validation sets\n",
    "print(\"Training Set:\")\n",
    "print(train_dataset)\n",
    "print(\"Validation Set:\")\n",
    "print(eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [1, 774, 5491, 28747, 28705, 28750, 28734, 28750, 28740, 28733, 28734, 28783, 28733, 28740, 28783, 28705, 28734, 28734, 28747, 28734, 28734, 28747, 28734, 28734, 28705, 13, 27332, 6096, 486, 413, 21111, 28706, 272, 13311, 28747, 13, 28705, 28740, 28723, 9900, 477, 17396, 28709, 13, 28750, 28723, 4121, 26469, 266, 28705, 13, 28770, 28723, 1725, 4649, 315, 5591, 778, 3536, 302, 19587, 20637, 13, 28781, 28723, 11482, 276, 325, 7781, 262, 1772, 28731, 13, 28782, 28723, 23330, 385, 24743, 13, 28784, 28723, 315, 28877, 10270, 13, 28787, 28723, 25363, 1337, 2450, 13, 28783, 28723, 4157, 420, 595, 13, 28774, 28723, 330, 487, 28715, 1780, 28717, 13, 28740, 28734, 28723, 5702, 424, 28709, 16073, 603, 28709, 28705, 13, 28740, 28740, 28723, 5376, 691, 367, 20368, 12216, 28764, 13, 28740, 28750, 28723, 5013, 1437, 14812, 463, 7645, 262, 13, 28740, 28770, 28723, 9764, 380, 367, 326, 1495, 13, 13, 28740, 28723, 11482, 276, 325, 362, 3689, 473, 28731, 13, 28750, 28723, 11641, 16159, 1812, 13, 28770, 28723, 15765, 28724, 334, 2443, 28738, 2443, 13, 28781, 28723, 475, 897, 272, 2025, 13985, 13, 28782, 28723, 418, 380, 1778, 1198, 13, 28784, 28723, 10920, 401, 18361, 13, 28787, 28723, 9766, 28717, 21769, 28709, 13, 28783, 28723, 5040, 28729, 28715, 988, 28710, 13, 28774, 28723, 9360, 13796, 13, 28740, 28734, 28723, 4168, 1262, 13, 28740, 28740, 28723, 7833, 1343, 6873, 424, 28709, 13, 28740, 28750, 28723, 1888, 1158, 22064, 13, 28740, 28770, 28723, 6624, 262, 28289, 13, 28740, 28781, 28723, 17311, 26103, 1905, 13, 28740, 28782, 28723, 1739, 581, 28070, 13, 28740, 28784, 28723, 8179, 643, 28720, 715, 28705, 13, 28740, 28787, 28723, 5459, 9143, 13, 28740, 28783, 28723, 1739, 581, 28070, 28705, 13, 13, 28740, 28723, 11819, 560, 338, 4222, 13, 28750, 28723, 1325, 18651, 3197, 2705, 13, 28770, 28723, 1325, 18651, 1054, 1150, 323, 13, 28781, 28723, 16506, 4222, 13, 28782, 28723, 5824, 1010, 296, 13, 28784, 28723, 2215, 6083, 13, 13, 28740, 28723, 17038, 13, 28750, 28723, 18742, 10973, 4401, 13, 13, 28740, 28723, 8285, 781, 6428, 5365, 13, 13, 28740, 28723, 10390, 13178, 1061, 13, 13, 28740, 28723, 320, 978, 7003, 28814, 387, 13834, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = train_dataset[0]\n",
    "# print(formatting_func(row))\n",
    "x = tokenizer(\n",
    "        formatting_func(row),\n",
    "        truncation=True,\n",
    "        max_length=max_sequence_length,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize the Data Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_tokenize_prompt(row):\n",
    "    result = tokenizer(\n",
    "        formatting_func(row),\n",
    "        truncation=True,\n",
    "        max_length=max_sequence_length,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff49dddb3f2743c99ae8a68ccff41244",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/633 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95fcef0a2034499f9cde7066bf137f6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/71 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train_dataset = train_dataset.map(generate_and_tokenize_prompt)\n",
    "tokenized_val_dataset = eval_dataset.map(generate_and_tokenize_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['date', 'note', 'input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 633\n",
       "})"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Examples:\n",
      "Example 1 - Date: 2021-08-18 00:00:00\n",
      "Input IDs: [1, 774, 5491, 28747, 28705, 28750, 28734, 28750, 28740, 28733]... [Total: 1500]\n",
      "Attention Mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]...\n",
      "Labels: [1, 774, 5491, 28747, 28705, 28750, 28734, 28750, 28740, 28733]...\n",
      "\n",
      "Example 2 - Date: 2021-08-08 00:00:00\n",
      "Input IDs: [1, 774, 5491, 28747, 28705, 28750, 28734, 28750, 28740, 28733]... [Total: 1500]\n",
      "Attention Mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]...\n",
      "Labels: [1, 774, 5491, 28747, 28705, 28750, 28734, 28750, 28740, 28733]...\n",
      "\n",
      "Example 3 - Date: 2022-04-03 00:00:00\n",
      "Input IDs: [1, 774, 5491, 28747, 28705, 28750, 28734, 28750, 28750, 28733]... [Total: 1500]\n",
      "Attention Mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]...\n",
      "Labels: [1, 774, 5491, 28747, 28705, 28750, 28734, 28750, 28750, 28733]...\n",
      "\n",
      "Example 4 - Date: 2023-08-21 00:00:00\n",
      "Input IDs: [1, 774, 5491, 28747, 28705, 28750, 28734, 28750, 28770, 28733]... [Total: 1500]\n",
      "Attention Mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]...\n",
      "Labels: [1, 774, 5491, 28747, 28705, 28750, 28734, 28750, 28770, 28733]...\n",
      "\n",
      "Example 5 - Date: 2022-06-28 00:00:00\n",
      "Input IDs: [1, 774, 5491, 28747, 28705, 28750, 28734, 28750, 28750, 28733]... [Total: 1500]\n",
      "Attention Mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]...\n",
      "Labels: [1, 774, 5491, 28747, 28705, 28750, 28734, 28750, 28750, 28733]...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inspect first few examples of the tokenized training dataset\n",
    "print(\"Training Dataset Examples:\")\n",
    "for i in range(5):\n",
    "    example = tokenized_train_dataset[i]\n",
    "    print(f\"Example {i+1} - Date: {example['date']}\")\n",
    "    print(f\"Input IDs: {example['input_ids'][:10]}... [Total: {len(example['input_ids'])}]\")\n",
    "    print(f\"Attention Mask: {example['attention_mask'][:10]}...\")\n",
    "    print(f\"Labels: {example['labels'][:10]}...\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Examples:\n",
      "Example 1: [1, 774, 5491, 28747, 28705, 28750, 28734, 28750, 28740, 28733, 28734, 28783, 28733, 28740, 28783, 28705, 28734, 28734, 28747, 28734, 28734, 28747, 28734, 28734, 28705, 13, 27332, 6096, 486, 413, 21111, 28706, 272, 13311, 28747, 13, 28705, 28740, 28723, 9900, 477, 17396, 28709, 13, 28750, 28723, 4121, 26469, 266, 28705, 13, 28770, 28723, 1725, 4649, 315, 5591, 778, 3536, 302, 19587, 20637, 13, 28781, 28723, 11482, 276, 325, 7781, 262, 1772, 28731, 13, 28782, 28723, 23330, 385, 24743, 13, 28784, 28723, 315, 28877, 10270, 13, 28787, 28723, 25363, 1337, 2450, 13, 28783, 28723, 4157, 420, 595, 13, 28774, 28723, 330, 487, 28715, 1780, 28717, 13, 28740, 28734, 28723, 5702, 424, 28709, 16073, 603, 28709, 28705, 13, 28740, 28740, 28723, 5376, 691, 367, 20368, 12216, 28764, 13, 28740, 28750, 28723, 5013, 1437, 14812, 463, 7645, 262, 13, 28740, 28770, 28723, 9764, 380, 367, 326, 1495, 13, 13, 28740, 28723, 11482, 276, 325, 362, 3689, 473, 28731, 13, 28750, 28723, 11641, 16159, 1812, 13, 28770, 28723, 15765, 28724, 334, 2443, 28738, 2443, 13, 28781, 28723, 475, 897, 272, 2025, 13985, 13, 28782, 28723, 418, 380, 1778, 1198, 13, 28784, 28723, 10920, 401, 18361, 13, 28787, 28723, 9766, 28717, 21769, 28709, 13, 28783, 28723, 5040, 28729, 28715, 988, 28710, 13, 28774, 28723, 9360, 13796, 13, 28740, 28734, 28723, 4168, 1262, 13, 28740, 28740, 28723, 7833, 1343, 6873, 424, 28709, 13, 28740, 28750, 28723, 1888, 1158, 22064, 13, 28740, 28770, 28723, 6624, 262, 28289, 13, 28740, 28781, 28723, 17311, 26103, 1905, 13, 28740, 28782, 28723, 1739, 581, 28070, 13, 28740, 28784, 28723, 8179, 643, 28720, 715, 28705, 13, 28740, 28787, 28723, 5459, 9143, 13, 28740, 28783, 28723, 1739, 581, 28070, 28705, 13, 13, 28740, 28723, 11819, 560, 338, 4222, 13, 28750, 28723, 1325, 18651, 3197, 2705, 13, 28770, 28723, 1325, 18651, 1054, 1150, 323, 13, 28781, 28723, 16506, 4222, 13, 28782, 28723, 5824, 1010, 296, 13, 28784, 28723, 2215, 6083, 13, 13, 28740, 28723, 17038, 13, 28750, 28723, 18742, 10973, 4401, 13, 13, 28740, 28723, 8285, 781, 6428, 5365, 13, 13, 28740, 28723, 10390, 13178, 1061, 13, 13, 28740, 28723, 320, 978, 7003, 28814, 387, 13834, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "Example 2: [1, 774, 5491, 28747, 28705, 28750, 28734, 28750, 28740, 28733, 28734, 28783, 28733, 28734, 28783, 28705, 28734, 28734, 28747, 28734, 28734, 28747, 28734, 28734, 28705, 13, 27332, 6096, 486, 413, 21111, 28706, 272, 13311, 28747, 13, 1387, 349, 708, 4865, 438, 272, 11997, 10305, 28723, 9954, 378, 28809, 28713, 799, 319, 748, 28723, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "Example 3: [1, 774, 5491, 28747, 28705, 28750, 28734, 28750, 28750, 28733, 28734, 28781, 28733, 28734, 28770, 28705, 28734, 28734, 28747, 28734, 28734, 28747, 28734, 28734, 28705, 13, 27332, 6096, 486, 413, 21111, 28706, 272, 13311, 28747, 13, 11530, 533, 2430, 302, 264, 6965, 10301, 13, 22467, 264, 2838, 1059, 378, 13, 14454, 368, 295, 645, 320, 849, 14563, 10506, 325, 28707, 16245, 1250, 15131, 312, 301, 28731, 369, 1347, 264, 5427, 302, 10506, 2553, 369, 1316, 298, 1912, 264, 521, 1799, 2928, 690, 349, 13382, 297, 272, 277, 3777, 28723, 28705, 13, 1227, 645, 533, 2430, 460, 272, 8825, 369, 7290, 264, 2188, 28809, 28713, 4501, 304, 625, 706, 298, 272, 25365, 28809, 28713, 2191, 2884, 13, 9458, 396, 7938, 304, 264, 264, 1326, 23101, 1192, 297, 1221, 302, 264, 16544, 4636, 1192, 20382, 395, 574, 7938, 304, 8015, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "Example 4: [1, 774, 5491, 28747, 28705, 28750, 28734, 28750, 28770, 28733, 28734, 28783, 28733, 28750, 28740, 28705, 28734, 28734, 28747, 28734, 28734, 28747, 28734, 28734, 28705, 13, 27332, 6096, 486, 413, 21111, 28706, 272, 13311, 28747, 13, 816, 553, 7197, 2098, 3142, 354, 989, 3316, 356, 8513, 970, 478, 12143, 578, 5397, 544, 272, 1722, 478, 2613, 298, 511, 298, 1430, 799, 28723, 315, 15124, 1973, 19017, 304, 15441, 516, 17393, 302, 7714, 528, 297, 798, 354, 272, 1526, 298, 1032, 28723, 650, 403, 4497, 1800, 582, 304, 2897, 778, 264, 16624, 28724, 4159, 5599, 28723, 650, 403, 264, 10386, 304, 315, 403, 272, 2760, 287, 7041, 400, 11226, 438, 395, 544, 272, 1659, 302, 516, 6965, 8646, 28723, 2530, 264, 2102, 302, 708, 3142, 395, 1430, 799, 28725, 456, 2770, 579, 7714, 1179, 28723, 816, 2068, 1059, 264, 8654, 11780, 1312, 400, 4142, 575, 302, 17870, 28723, 650, 403, 26159, 1007, 369, 315, 863, 459, 1316, 713, 395, 272, 2318, 304, 400, 553, 298, 511, 2905, 356, 516, 1216, 28723, 650, 16282, 528, 28725, 400, 403, 10545, 28725, 562, 3534, 1060, 400, 403, 776, 7350, 304, 863, 459, 1601, 737, 264, 11801, 298, 528, 28723, 2530, 264, 10355, 7839, 1819, 369, 1749, 528, 4622, 10214, 482, 684, 813, 3758, 26248, 28725, 478, 4251, 5048, 264, 3298, 3414, 304, 400, 7160, 3125, 298, 1565, 852, 582, 298, 528, 28723, 650, 2068, 298, 18279, 456, 2609, 9071, 304, 315, 459, 865, 3395, 713, 272, 2764, 298, 3555, 2722, 562, 315, 835, 4429, 713, 582, 304, 13164, 286, 713, 395, 21147, 304, 2016, 28723, 315, 829, 459, 3229, 264, 727, 478, 2270, 2770, 7887, 28723, 1537, 8760, 28725, 579, 297, 2016, 28725, 579, 3142, 1323, 27024, 354, 624, 1698, 28723, 661, 28809, 28713, 767, 478, 553, 1560, 750, 5345, 354, 272, 3293, 879, 304, 264, 2795, 478, 28809, 28715, 750, 2548, 456, 9773, 28723, 28705, 13, 13, 7337, 456, 9071, 28725, 272, 3028, 302, 19017, 1250, 18940, 298, 2493, 1112, 6774, 528, 395, 17790, 369, 1191, 28715, 1006, 778, 7665, 1007, 26159, 466, 28723, 2530, 456, 9071, 28725, 315, 1601, 9534, 684, 272, 11450, 302, 2461, 264, 18173, 369, 349, 579, 634, 19821, 28723, 315, 837, 12434, 4134, 586, 17393, 302, 6252, 713, 4159, 1698, 1338, 28723, 1791, 1032, 713, 16497, 1565, 272, 12937, 284, 23215, 302, 264, 1628, 4531, 369, 478, 6665, 2553, 28723, 1791, 347, 575, 297, 798, 438, 264, 11997, 1951, 304, 347, 14192, 1332, 486, 272, 6965, 21007, 1401, 592, 3210, 821, 937, 28709, 309, 778, 1008, 9994, 6217, 28723, 661, 8315, 737, 1722, 829, 1528, 347, 1545, 456, 727, 28723, 5410, 315, 541, 1528, 1346, 592, 347, 1545, 456, 727, 28723, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "Example 5: [1, 774, 5491, 28747, 28705, 28750, 28734, 28750, 28750, 28733, 28734, 28784, 28733, 28750, 28783, 28705, 28734, 28734, 28747, 28734, 28734, 28747, 28734, 28734, 28705, 13, 27332, 6096, 486, 413, 21111, 28706, 272, 13311, 28747, 13, 1387, 460, 741, 1722, 369, 4243, 456, 9071, 369, 315, 837, 10268, 1197, 684, 3653, 684, 1096, 315, 682, 3210, 6409, 706, 575, 28723, 1092, 315, 837, 3687, 3416, 272, 9388, 302, 706, 10876, 1103, 1055, 579, 5230, 3653, 622, 1316, 528, 4563, 25312, 390, 378, 1743, 659, 28723, 28705, 13, 13, 415, 9071, 3125, 395, 2719, 778, 11800, 28743, 356, 10983, 6856, 1401, 28705, 28784, 3419, 28723, 315, 553, 750, 7946, 272, 3293, 1819, 304, 9638, 298, 26039, 28723, 7336, 459, 4622, 9534, 684, 14384, 304, 4622, 13387, 4358, 27524, 684, 27656, 28723, 1387, 654, 741, 1353, 4382, 1444, 592, 369, 654, 3344, 582, 264, 2055, 302, 2764, 28723, 315, 2770, 2082, 1753, 477, 713, 28725, 315, 2770, 5256, 438, 272, 1654, 302, 713, 28723, 1387, 403, 708, 20984, 1444, 592, 9229, 304, 315, 403, 12785, 767, 478, 654, 2548, 456, 544, 354, 28723, 25020, 478, 2942, 298, 28308, 3123, 1545, 369, 682, 865, 2270, 2588, 1076, 297, 264, 4733, 28804, 315, 403, 4622, 1008, 9994, 684, 459, 2461, 707, 1353, 6400, 354, 14384, 3536, 302, 27656, 28723, 315, 553, 272, 15551, 28725, 562, 315, 863, 459, 506, 272, 3282, 28723, 1770, 25882, 1145, 28725, 708, 4938, 302, 3282, 28723, 1094, 19717, 1184, 390, 1743, 28723, 315, 2016, 11800, 28743, 562, 378, 659, 1743, 750, 264, 23275, 1633, 354, 528, 28723, 1984, 2970, 12293, 7237, 15356, 304, 396, 18284, 1274, 302, 4159, 5369, 28715, 497, 28725, 562, 708, 1353, 304, 2848, 1832, 14498, 28723, 28705, 13, 13, 315, 6792, 297, 11710, 13354, 438, 28705, 28781, 28747, 28770, 28734, 28720, 304, 1269, 378, 298, 4246, 24394, 297, 2108, 821, 9418, 3486, 28723, 315, 835, 1988, 298, 272, 2990, 395, 272, 5161, 1269, 369, 315, 682, 347, 5272, 298, 15784, 297, 272, 2949, 28723, 6880, 1856, 5307, 354, 27656, 304, 315, 298, 25993, 28723, 1824, 460, 478, 2548, 28804, 13, 13, 315, 403, 356, 272, 27430, 395, 586, 8040, 2210, 304, 264, 1439, 276, 14233, 23598, 770, 363, 1748, 297, 586, 1021, 739, 315, 3364, 2493, 1034, 586, 1141, 28723, 661, 403, 27656, 28723, 650, 403, 15603, 737, 264, 319, 2558, 28724, 1628, 4531, 438, 272, 7739, 302, 528, 28723, 560, 12244, 2016, 272, 676, 659, 354, 528, 304, 378, 8724, 528, 582, 28723, 3348, 28718, 2569, 544, 272, 9388, 302, 981, 6802, 460, 478, 2548, 28838, 304, 14795, 528, 2079, 28747, 1096, 400, 13468, 528, 28723, 5518, 400, 2870, 528, 4610, 28723, 1092, 349, 272, 13967, 1132, 390, 1162, 28804, 2378, 315, 1038, 713, 4610, 28804, 2378, 315, 2016, 713, 852, 28804, 13, 13, 816, 5825, 298, 2647, 438, 516, 1633, 438, 28705, 28784, 28747, 28770, 28734, 354, 7854, 28723, 315, 20212, 586, 2475, 8040, 2210, 298, 1739, 14698, 28809, 28713, 9585, 438, 28705, 28770, 28750, 28782, 13043, 14257, 28723, 661, 403, 264, 5401, 4622, 302, 10853, 298, 506, 586, 1216, 24309, 4084, 354, 272, 9071, 28723, 23971, 636, 28723, 2378, 459, 927, 298, 15187, 356, 3637, 387, 369, 3637, 1250, 27656, 28723, 28705, 13, 13, 315, 6792, 438, 27656, 28809, 28713, 354, 7854, 3909, 1096, 315, 403, 281, 3204, 288, 28725, 690, 400, 1580, 506, 11012, 1096, 400, 403, 544, 754, 528, 390, 3403, 390, 315, 1433, 736, 28723, 1684, 272, 2251, 302, 516, 9585, 5051, 2910, 528, 28725, 400, 403, 356, 528, 28723, 8571, 286, 13821, 4855, 1060, 586, 10807, 737, 400, 1743, 1235, 304, 264, 4622, 302, 1558, 786, 28711, 617, 1404, 754, 528, 390, 378, 1743, 1235, 739, 400, 8374, 274, 528, 1135, 410, 2834, 304, 18925, 737, 369, 28723, 315, 12794, 586, 2187, 395, 516, 13821, 297, 586, 5108, 304, 913, 354, 264, 14123, 28725, 264, 5132, 28725, 2424, 28725, 562, 315, 1743, 1567, 582, 4606, 12752, 28723, 415, 4788, 369, 315, 511, 459, 947, 713, 4564, 497, 528, 13551, 778, 586, 2273, 28723, 315, 541, 1601, 3561, 576, 20936, 304, 20936, 1753, 28723, 28705, 13, 13, 650, 403, 2097, 708, 727, 304, 11164, 528, 298, 272, 9384, 28723, 2354, 1741, 304, 19279, 9585, 8617, 528, 805, 28723, 315, 28809, 28719, 27587, 356, 586, 11752, 390, 400, 319, 1506, 274, 528, 304, 1003, 8803, 586, 8155, 1996, 315, 28809, 28719, 15913, 3741, 354, 586, 3075, 1964, 12563, 27987, 28723, 650, 349, 356, 1830, 302, 528, 304, 295, 1804, 288, 516, 23108, 778, 586, 1155, 19764, 28723, 315, 541, 1912, 400, 349, 2942, 298, 511, 767, 315, 28809, 333, 9621, 713, 298, 511, 298, 771, 528, 778, 378, 28723, 650, 14259, 20600, 28713, 516, 23108, 1444, 586, 19764, 562, 272, 1335, 302, 516, 23108, 1235, 459, 4067, 586, 9697, 737, 315, 947, 378, 298, 28723, 661, 3127, 302, 776, 11662, 2267, 586, 1155, 9551, 304, 341, 4737, 586, 261, 1690, 28723, 315, 541, 1601, 713, 1149, 298, 1464, 298, 1658, 378, 297, 304, 586, 2187, 261, 4839, 28723, 315, 949, 28809, 28707, 947, 378, 28723, 1684, 400, 11164, 516, 2105, 1060, 298, 6683, 304, 12345, 516, 5108, 356, 586, 5108, 315, 541, 9230, 1545, 21273, 294, 356, 713, 369, 315, 949, 28809, 28707, 737, 28723, 650, 12345, 264, 1628, 2286, 302, 516, 23108, 297, 528, 304, 3418, 509, 28723, 315, 14905, 562, 1464, 298, 7786, 3561, 1059, 378, 28723, 8285, 498, 28725, 8096, 28725, 625, 778, 378, 28723, 1092, 315, 511, 459, 506, 272, 622, 298, 625, 778, 378, 28723, 560, 264, 1480, 4261, 298, 4602, 456, 2659, 477, 1250, 6312, 354, 528, 28725, 315, 1721, 1753, 477, 713, 304, 1527, 3561, 1401, 579, 369, 315, 837, 11981, 713, 28723, 315, 1601, 272, 15802, 1444, 592, 390, 315, 1388, 2602, 28723, 851, 349, 459, 272, 907, 727, 315, 506, 7098, 1753, 477, 713, 28723, 650, 5960, 315, 837, 1856, 298, 4665, 304, 349, 13665, 304, 356, 1486, 10977, 28723, 315, 8864, 707, 1504, 297, 396, 4261, 298, 347, 1960, 294, 1197, 684, 586, 3208, 28723, 28705, 13, 13, 981, 8779, 28809, 28713, 5789, 264, 1628, 680, 3372, 315, 1315, 544, 9155, 298, 272, 1639, 369, 315, 506, 750, 11981, 1753, 477, 713, 272, 3293, 727, 28723, 981, 16488, 3372, 400, 773, 818, 286, 722, 346, 304, 868, 315, 27594, 1627, 410, 28723, 981, 6155, 586, 5525, 3372, 315, 1654, 298, 3561, 28725, 981, 314, 315, 459, 3587, 2141, 28804, 650, 10175, 1658, 272, 7230, 297, 2435, 315, 9303, 272, 1654, 304, 1388, 516, 2105, 297, 586, 3038, 304, 8374, 713, 21147, 1999, 356, 272, 5108, 28723, 650, 4347, 2400, 302, 586, 2187, 304, 6098, 516, 1982, 298, 4274, 528, 24324, 579, 369, 315, 837, 18116, 1076, 562, 315, 14905, 304, 5696, 852, 28723, 981, 6017, 28809, 28707, 1464, 298, 2602, 378, 3372, 315, 1315, 2526, 778, 516, 2282, 28723, 981, 8779, 528, 347, 7413, 302, 456, 1368, 2435, 315, 873, 369, 400, 5659, 298, 347, 297, 2602, 28723, 315, 873, 369, 528, 2177, 288, 3561, 739, 400, 349, 6495, 298, 347, 272, 18669, 624, 15667, 272, 13050, 562, 315, 947, 298, 1038, 456, 771, 354, 272, 1560, 302, 592, 28723, 650, 349, 13665, 304, 395, 516, 2105, 1309, 297, 586, 3038, 28725, 315, 1912, 713, 298, 913, 438, 528, 28723, 315, 1388, 264, 3534, 5276, 304, 3232, 356, 272, 23413, 302, 586, 5276, 298, 10325, 3561, 297, 3317, 369, 586, 2282, 1565, 304, 5034, 713, 28723, 816, 913, 778, 1430, 799, 28809, 28713, 2282, 304, 315, 312, 512, 473, 5380, 586, 852, 395, 586, 7969, 1565, 354, 713, 28723, 28705, 13, 13, 315, 23420, 299, 346, 1719, 3985, 586, 9697, 395, 586, 2991, 304, 4986, 9728, 304, 2968, 706, 298, 586, 9948, 354, 264, 11016, 1369, 28723, 14510, 28723, 1725, 28809, 28713, 739, 315, 8168, 28725, 378, 28809, 28713, 586, 9697, 369, 991, 8855, 737, 1627, 410, 387, 378, 28809, 28713, 27656, 28809, 28713, 5276, 28723, 28705, 13, 13, 315, 947, 298, 17026, 354, 264, 2470, 477, 3653, 272, 3926, 302, 456, 15642, 298, 1315, 369, 1016, 2449, 272, 11412, 349, 390, 3031, 25924, 354, 528, 390, 378, 349, 16066, 6219, 28723, 1824, 3653, 456, 8922, 528, 349, 459, 369, 315, 837, 459, 297, 2016, 395, 27656, 1096, 302, 24815, 442, 586, 4461, 440, 22417, 3238, 28723, 661, 28809, 28713, 1096, 400, 349, 459, 272, 624, 304, 400, 622, 1484, 347, 28723, 315, 837, 459, 3142, 1323, 18940, 298, 27656, 390, 264, 1830, 690, 349, 264, 2700, 1096, 369, 28809, 28713, 544, 400, 5960, 910, 298, 511, 28723, 661, 349, 3031, 25924, 298, 8168, 1167, 1722, 442, 349, 378, 776, 264, 1856, 10837, 298, 25993, 28804, 1015, 2079, 349, 378, 579, 1856, 298, 25993, 28804, 1047, 456, 349, 272, 5307, 28725, 690, 378, 349, 1096, 456, 349, 910, 315, 1601, 28725, 868, 378, 349, 297, 1560, 302, 813, 10299, 298, 2115, 767, 478, 460, 2548, 579, 369, 400, 304, 315, 993, 1560, 1300, 15079, 395, 1698, 28723, 315, 837, 459, 297, 2016, 395, 27656, 562, 315, 511, 2016, 713, 28723, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "\n",
      "Validation Dataset Examples:\n",
      "Example 1: [1, 774, 5491, 28747, 28705, 28750, 28734, 28750, 28740, 28733, 28734, 28774, 28733, 28734, 28750, 28705, 28734, 28734, 28747, 28734, 28734, 28747, 28734, 28734, 28705, 13, 27332, 6096, 486, 413, 21111, 28706, 272, 13311, 28747, 13, 918, 28792, 28750, 28734, 28750, 28740, 28733, 28734, 28774, 28733, 28734, 28750, 28733, 28749, 7675, 5121, 10341, 28748, 28750, 28734, 28750, 28740, 28733, 28734, 28774, 28733, 28734, 28750, 28733, 28749, 7675, 28723, 28768, 16600, 28731, 13, 13, 28737, 28809, 333, 1484, 2613, 2493, 272, 1348, 1069, 315, 2613, 368, 28723, 315, 28809, 28719, 1864, 315, 28809, 333, 750, 680, 18940, 298, 905, 390, 264, 2894, 28723, 1092, 736, 403, 1545, 478, 553, 28725, 1545, 579, 2841, 304, 9964, 28723, 661, 403, 739, 368, 947, 2493, 28725, 544, 302, 2493, 28725, 579, 11869, 369, 1019, 652, 19279, 349, 1179, 28723, 28705, 13, 13, 2428, 264, 10835, 1155, 3075, 676, 28725, 315, 873, 28723, 1725, 28809, 28713, 4668, 767, 315, 737, 28723, 7670, 693, 460, 14897, 6142, 28723, 1770, 513, 28713, 28725, 304, 28713, 442, 562, 28713, 684, 378, 28723, 5673, 390, 264, 10835, 6635, 301, 28723, 11081, 297, 652, 1407, 465, 369, 829, 2270, 347, 26236, 354, 2424, 562, 3075, 28723, 4315, 28804, 415, 1348, 2611, 24964, 372, 297, 5737, 4529, 10357, 8206, 5659, 17442, 1779, 28724, 11421, 28723, 12960, 9896, 601, 575, 302, 2687, 1467, 486, 264, 3075, 676, 442, 2971, 28809, 28713, 2016, 349, 264, 15642, 390, 1571, 390, 1250, 2687, 3837, 28723, 19422, 473, 369, 395, 2461, 264, 9130, 3075, 12408, 480, 2947, 582, 3416, 368, 304, 28364, 1012, 624, 302, 871, 3442, 778, 368, 28725, 304, 1055, 369, 28809, 28713, 776, 264, 18337, 17393, 5298, 1080, 2930, 12957, 296, 28723, 5740, 276, 403, 4319, 22608, 601, 395, 528, 28723, 650, 403, 390, 13803, 486, 528, 390, 400, 403, 4319, 22608, 601, 28723, 1984, 5941, 403, 624, 302, 272, 1722, 369, 13803, 713, 28723, 650, 3851, 298, 1300, 272, 2687, 297, 528, 28723, 320, 1638, 298, 9550, 2275, 378, 28723, 650, 773, 304, 863, 1722, 10795, 1781, 298, 586, 5941, 369, 654, 521, 1392, 28721, 449, 522, 28725, 562, 315, 12706, 458, 713, 707, 1504, 28723, 650, 12706, 458, 528, 1368, 28723, 315, 829, 459, 275, 874, 272, 1982, 302, 5941, 1835, 713, 28725, 562, 315, 5661, 3802, 5681, 799, 1982, 315, 553, 754, 713, 28723, 315, 863, 378, 6032, 3071, 304, 395, 272, 8284, 298, 6241, 28723, 1725, 28809, 28713, 272, 1970, 684, 544, 272, 3075, 1683, 315, 28809, 333, 2270, 21847, 28723, 1306, 460, 981, 24418, 1503, 28838, 297, 272, 3367, 369, 590, 1484, 2072, 298, 4244, 6241, 28725, 304, 2783, 28725, 6241, 10352, 298, 347, 4319, 7410, 286, 28723, 5673, 1683, 460, 1982, 28723, 5410, 264, 3339, 287, 2341, 693, 659, 459, 5996, 298, 2602, 516, 11750, 28725, 3075, 1683, 28809, 28713, 1982, 304, 23037, 349, 396, 4783, 380, 304, 26299, 1970, 3416, 302, 706, 28723, 415, 10386, 297, 272, 484, 1380, 5126, 13836, 863, 459, 2072, 298, 1721, 2905, 28725, 562, 369, 349, 272, 1069, 302, 272, 10386, 28723, 1387, 403, 708, 8284, 298, 6241, 562, 1722, 1309, 7054, 582, 480, 17109, 544, 754, 272, 4366, 28723, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "Example 2: [1, 774, 5491, 28747, 28705, 28750, 28734, 28750, 28750, 28733, 28734, 28774, 28733, 28750, 28784, 28705, 28734, 28734, 28747, 28734, 28734, 28747, 28734, 28734, 28705, 13, 27332, 6096, 486, 413, 21111, 28706, 272, 13311, 28747, 13, 315, 28809, 28719, 264, 2990, 4531, 5381, 304, 6333, 28723, 1537, 2990, 369, 315, 949, 28809, 28707, 1019, 506, 264, 6801, 28723, 1537, 739, 2493, 2278, 298, 528, 12313, 528, 298, 408, 3461, 272, 15837, 6396, 297, 272, 6607, 334, 1164, 266, 354, 5435, 2202, 28725, 315, 403, 10816, 279, 440, 28723, 2961, 28725, 356, 272, 799, 2081, 302, 369, 1411, 8634, 6596, 28725, 315, 541, 28809, 28707, 3091, 315, 403, 2270, 8526, 28723, 12960, 297, 4735, 356, 264, 2184, 369, 8435, 395, 741, 302, 272, 1489, 905, 315, 28809, 333, 2270, 1424, 403, 272, 12144, 302, 586, 5561, 28723, 330, 6596, 737, 369, 4435, 264, 1338, 28725, 378, 5785, 4648, 528, 28723, 7812, 368, 298, 19017, 401, 2158, 354, 1304, 4328, 528, 28725, 298, 7149, 567, 11410, 9900, 354, 2492, 378, 544, 4804, 28725, 298, 3376, 693, 3246, 2005, 356, 369, 7782, 28878, 304, 298, 3561, 354, 3344, 264, 4676, 28723, 1824, 264, 7714, 15982, 28723, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "Example 3: [1, 774, 5491, 28747, 28705, 28750, 28734, 28750, 28740, 28733, 28734, 28740, 28733, 28750, 28784, 28705, 28734, 28734, 28747, 28734, 28734, 28747, 28734, 28734, 28705, 13, 27332, 6096, 486, 413, 21111, 28706, 272, 13311, 28747, 13, 14213, 28725, 1250, 11997, 28725, 9391, 13, 13547, 14204, 732, 1008, 17271, 13, 13, 6058, 288, 297, 14130, 13, 20802, 948, 28725, 4686, 1847, 304, 22363, 13, 13, 5816, 460, 989, 5444, 12690, 1236, 28747, 6965, 472, 567, 5024, 28723, 415, 989, 541, 2588, 390, 989, 7681, 3270, 22796, 28723, 2387, 349, 865, 8504, 28725, 1500, 25101, 28725, 3270, 22962, 304, 272, 799, 349, 320, 6439, 6607, 1084, 28723, 1015, 868, 736, 349, 272, 2195, 23267, 3142, 2708, 1307, 298, 11711, 586, 1216, 13421, 304, 625, 20334, 28724, 28723, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "Example 4: [1, 774, 5491, 28747, 28705, 28750, 28734, 28750, 28770, 28733, 28734, 28770, 28733, 28734, 28740, 28705, 28734, 28734, 28747, 28734, 28734, 28747, 28734, 28734, 28705, 13, 27332, 6096, 486, 413, 21111, 28706, 272, 13311, 28747, 13, 4583, 18388, 528, 739, 315, 1315, 369, 349, 586, 12782, 28723, 4583, 18388, 528, 739, 315, 1315, 369, 378, 349, 1484, 586, 12782, 298, 25482, 368, 28723, 661, 659, 750, 264, 3796, 989, 1267, 1444, 272, 989, 302, 592, 28723, 415, 799, 2125, 368, 773, 298, 528, 28725, 3475, 28737, 506, 459, 3214, 264, 2470, 754, 272, 2609, 989, 1267, 298, 347, 15131, 442, 544, 369, 368, 506, 2203, 298, 528, 18526, 1725, 1528, 24215, 297, 354, 528, 1096, 369, 349, 910, 315, 506, 2770, 28723, 2378, 368, 459, 1601, 586, 2016, 354, 368, 28804, 2378, 368, 459, 1601, 910, 1188, 315, 947, 368, 298, 347, 7413, 302, 544, 456, 28804, 2378, 368, 459, 1032, 910, 1188, 315, 5055, 536, 304, 616, 431, 368, 304, 574, 26719, 304, 2905, 368, 506, 2203, 298, 1038, 456, 8123, 2572, 10584, 28705, 13, 13, 981, 28737, 863, 459, 1743, 1032, 378, 1096, 315, 863, 459, 1743, 3091, 378, 28723, 1092, 315, 511, 1032, 378, 1055, 304, 315, 511, 3091, 378, 28723, 661, 349, 264, 23957, 1970, 298, 25884, 298, 2493, 737, 456, 28723, 1791, 4893, 369, 739, 315, 1021, 754, 586, 3031, 369, 368, 2400, 378, 395, 1179, 12782, 28723, 1725, 368, 622, 459, 21987, 378, 297, 574, 3038, 2435, 13, 13, 28835, 6017, 28809, 28707, 7120, 369, 586, 3031, 349, 297, 574, 3038, 28725, 1368, 28723, 315, 9081, 298, 2400, 13010, 395, 272, 3734, 2284, 2016, 304, 20151, 1019, 739, 315, 949, 28809, 28707, 1601, 737, 368, 460, 2548, 272, 1348, 395, 6683, 28723, 661, 659, 750, 264, 10342, 989, 1267, 28723, 1047, 2493, 2672, 272, 2609, 320, 6439, 304, 910, 400, 14113, 286, 395, 528, 28725, 590, 682, 506, 773, 28725, 3475, 527, 369, 1338, 575, 302, 574, 1411, 18526, 315, 949, 28809, 28707, 873, 369, 320, 6439, 9229, 28723, 315, 873, 456, 320, 6439, 28723, 1602, 368, 506, 4923, 298, 528, 304, 298, 14877, 349, 4672, 28723, 816, 1032, 368, 28723, 315, 1743, 2672, 368, 304, 315, 16437, 369, 368, 682, 1567, 575, 302, 574, 21729, 28723, 1015, 1236, 368, 460, 28723, 2961, 369, 368, 460, 1236, 28725, 949, 28809, 28707, 14393, 574, 2061, 28723, 1387, 622, 347, 1856, 9235, 28725, 736, 622, 347, 9235, 739, 368, 1601, 368, 927, 298, 1527, 1753, 28725, 562, 1464, 459, 298, 28723, 11442, 298, 2943, 716, 400, 6661, 369, 368, 773, 368, 2770, 297, 6611, 14836, 28723, 1684, 1722, 6139, 297, 813, 10616, 304, 590, 460, 459, 272, 1348, 3459, 7391, 1467, 28725, 873, 369, 1019, 868, 272, 6661, 349, 1309, 736, 28723, 1725, 368, 460, 6045, 2435, 28705, 13, 13, 315, 2056, 516, 1021, 304, 4163, 713, 852, 3416, 28723, 981, 28737, 947, 298, 6139, 586, 2273, 673, 477, 3475, 5845, 541, 315, 347, 6117, 28804, 28809, 298, 3475, 5845, 541, 315, 5116, 28804, 28809, 28838, 13, 13, 28835, 5613, 28808, 5592, 28723, 1529, 19241, 28723, 315, 14257, 2905, 369, 315, 829, 304, 1433, 579, 1188, 680, 821, 315, 829, 506, 16435, 297, 604, 2435, 28705, 13, 13, 981, 1313, 349, 459, 586, 4229, 16823, 298, 2111, 28723, 1984, 4735, 349, 298, 1008, 18018, 28745, 298, 2400, 5380, 586, 5823, 304, 298, 1388, 767, 315, 541, 28723, 315, 506, 298, 1943, 395, 456, 304, 5248, 575, 910, 541, 315, 2111, 28804, 1824, 541, 315, 2111, 10584, 13, 13, 1015, 579, 1055, 1236, 315, 837, 28725, 3653, 28725, 298, 3248, 456, 481, 3646, 269, 466, 354, 272, 1679, 727, 315, 1601, 22192, 28723, 1791, 3229, 298, 2943, 297, 877, 17113, 28725, 21869, 304, 20151, 1019, 739, 315, 837, 22192, 28723, 1791, 3229, 369, 456, 349, 459, 684, 528, 28723, 1984, 3208, 460, 459, 27731, 562, 590, 460, 459, 272, 865, 3208, 369, 1580, 347, 1424, 2477, 28723, 816, 460, 264, 2005, 304, 264, 5028, 28723, 315, 506, 298, 347, 1948, 705, 680, 821, 315, 837, 5982, 28723, 315, 506, 298, 2111, 680, 821, 315, 1675, 298, 625, 28723, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "Example 5: [1, 774, 5491, 28747, 28705, 28750, 28734, 28750, 28770, 28733, 28734, 28750, 28733, 28740, 28781, 28705, 28734, 28734, 28747, 28734, 28734, 28747, 28734, 28734, 28705, 13, 27332, 6096, 486, 413, 21111, 28706, 272, 13311, 28747, 13, 816, 1580, 347, 2358, 298, 3289, 356, 1430, 799, 28723, 1047, 1250, 2358, 298, 3924, 2016, 477, 624, 1698, 349, 1368, 1188, 298, 1460, 868, 456, 349, 459, 1404, 298, 771, 28723, 3489, 22972, 622, 11204, 28725, 17991, 302, 8773, 8418, 304, 2949, 28725, 562, 478, 1580, 1743, 347, 2112, 298, 624, 1698, 28723, 3782, 288, 1059, 2016, 1019, 739, 478, 460, 916, 6727, 349, 396, 960, 302, 12015, 646, 28745, 298, 347, 17508, 1019, 739, 478, 460, 6334, 28723, 5619, 460, 10421, 298, 10048, 1096, 28705, 13, 13, 7523, 18798, 28713, 460, 771, 304, 590, 460, 835, 11499, 28723, 542, 288, 349, 28725, 767, 478, 506, 1236, 349, 6517, 821, 264, 3758, 1096, 378, 349, 1404, 298, 2968, 1411, 298, 813, 6107, 374, 12232, 28723, 415, 4782, 349, 1430, 302, 22911, 28723, 8610, 582, 354, 1430, 799, 442, 949, 28809, 28707, 28723, 1047, 478, 511, 459, 1347, 582, 354, 1430, 799, 868, 478, 544, 1202, 28723, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "# Inspect first few examples of the tokenized training dataset\n",
    "print(\"Training Dataset Examples:\")\n",
    "for i in range(5):\n",
    "    print(f\"Example {i+1}: {tokenized_train_dataset[i]['input_ids']}\")\n",
    "\n",
    "# Inspect first few examples of the tokenized validation dataset\n",
    "print(\"\\nValidation Dataset Examples:\")\n",
    "for i in range(5):\n",
    "    print(f\"Example {i+1}: {tokenized_val_dataset[i]['input_ids']}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_journal_entries_mixtral",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
